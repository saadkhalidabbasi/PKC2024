{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Machine Algorithm Evaluation Through Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest Classifier\n",
      "Best Parameters are:  {'max_depth': 7, 'max_features': 'log2', 'min_samples_split': 3, 'n_estimators': 10}\n",
      "Best Score: 83.16740945326721\n",
      "Accuracy Score for  Random Forest Classifier is 0.8430493273542601\n",
      "\n",
      "\n",
      "Model: Decision Tree Classifier\n",
      "Best Parameters are:  {'max_depth': 5, 'min_samples_split': 2}\n",
      "Best Score: 81.81909484652564\n",
      "Accuracy Score for  Decision Tree Classifier is 0.8295964125560538\n",
      "\n",
      "\n",
      "Model: KNeighbour\n",
      "Best Parameters are:  {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Best Score: 71.72242797062331\n",
      "Accuracy Score for  KNeighbour is 0.9955156950672646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#  Loading DataSet\n",
    "df=sns.load_dataset('titanic')\n",
    "df['age']=df['age'].fillna(df['age'].mean())\n",
    "x=df[['age','fare','pclass','parch','sex','sibsp']]\n",
    "y=df['survived']\n",
    "x=pd.get_dummies(x,columns=['sex'])\n",
    "\n",
    "# Importing ML Algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Random ForestPrameter\n",
    "param_cv={'n_estimators':[10,50 ,100],\n",
    "          'min_samples_split':[2,3,4],\n",
    "          'max_depth':[3,5,7, None], \n",
    "          'max_features': ['log2','sqrt']}\n",
    "\n",
    "\n",
    "#  Decision Tree Parameter\n",
    "param_cvv={ 'max_depth':[3,5,7,None],'min_samples_split':[ 2,3,4]}\n",
    "\n",
    "# KNN Neighbour Parameter\n",
    "param_cvvv={'n_neighbors':[5,7],'weights':['uniform','distance']}\n",
    "\n",
    "models = [(RandomForestClassifier(),param_cv,'Random Forest Classifier'),\n",
    "          (DecisionTreeClassifier(),param_cvv,'Decision Tree Classifier'), \n",
    "          (KNeighborsClassifier(),param_cvvv,'KNeighbour')]\n",
    "# model_names = ['Random Forest Classifier','Decision Tree Classifer','KNN Classifier']\n",
    "for model,param_grid,model_names in models:\n",
    "    grid_search=GridSearchCV(model,param_grid,cv=5,scoring='accuracy')\n",
    "    grid_search.fit(x,y)\n",
    "    print(f\"Model: {model_names}\")\n",
    "    print('Best Parameters are: ',grid_search.best_params_)\n",
    "    print(\"Best Score:\",grid_search.best_score_*100)\n",
    "  \n",
    "    best_model=grid_search.best_estimator_\n",
    "    y_predict=best_model.predict(x_test)\n",
    "    accurac=accuracy_score(y_test,y_predict)\n",
    "    print('Accuracy Score for ',model_names,'is',accurac)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
